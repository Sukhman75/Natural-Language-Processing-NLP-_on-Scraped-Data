# Natural-Language-Processing-NLP-_on-Scraped-Data

As a very first step I am using my Quote_scraping project to fetch the text data from a website.

Second step is to do Text Mining on the fetched data, which consists of the following steps:
 1) Tokenizing the sentences(quotes) using RegexTokenizer which tokenizes the whole sentence into a list of words and drops all the punctuation from it. 
 2) Then I removed all the stop words from it. 
 3) This step includes adding Parts of Speech tags(pos_tags), tags every word with what it is like Noun, Pronoun, AdVerb, Verb, etc.

Third step includes finding the Frequency Distribution of the different part of speech and building a plot out of it. 


References: 
https://www.nltk.org
   
 


